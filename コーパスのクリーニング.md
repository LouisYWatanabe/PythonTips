# コーパスのクリーニング

```python
import re
import string
'''
コーパスクリーニング関数

テキストを小文字に変換
角括弧内のテキストを削除
リンクの削除
句読点の削除
数字を含む単語の削除
'''
def clean_text(text):
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    return text

# テキスト内の変換と削除
train['text'] = train['text'].apply(lambda x:clean_text(x))
train['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))
train.head()
```
```

textID	text	selected_text	sentiment	jaccard_score	Num_words_ST	Num_word_text	difference_in_words
0	cb774db0d1	id have responded if i were going	id have responded if i were going	neutral	1.000000	7	7	0
1	549e992a42	sooo sad i will miss you here in san diego	sooo sad	negative	0.200000	2	10	8
2	088c60f138	my boss is bullying me	bullying me	negative	0.166667	2	5	3
3	9642c003ef	what interview leave me alone	leave me alone	negative	0.600000	3	5	2
4	358bd9e861	sons of why couldnt they put them on the rel...	sons of	negative	0.214286	3	14	11
```

```python
# リスト内のテキストを空白で区切る
train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())
train['temp_list'].head()
```
```
0    [id, have, responded, if, i, were, going]
1                                  [sooo, sad]
2                               [bullying, me]
3                           [leave, me, alone]
4                                   [sons, of]
Name: temp_list, dtype: object
```
```python
# temp_list内の単語の出現頻度をリストとして取得
from collections import Counter
top = Counter([item for sublist in train['temp_list'] for item in sublist])
# 上位20単語を表示
top.most_common(20)
```
```
[('i', 7200),
 ('to', 5305),
 ('the', 4590),
 ('a', 3538),
 ('my', 2783),
 ('you', 2624),
 ('and', 2321),
 ('it', 2158),
 ('is', 2115),
 ('in', 1986),
 ('for', 1854),
 ('im', 1676),
 ('of', 1638),
 ('me', 1540),
 ('on', 1488),
 ('so', 1410),
 ('have', 1345),
 ('that', 1297),
 ('but', 1267),
 ('good', 1251)]
```

```python
# テキスト内で最も一般的な単語を表示
# 上位20単語をDataFrame型に変換
temp = pd.DataFrame(top.most_common(20))
# カラム名の作成
temp.columns = ['よく使われる言葉', 'count']
temp.style.background_gradient(cmap='Blues')
```
```
よく使われる言葉	count
0	i	7200
1	to	5305
2	the	4590
3	a	3538
4	my	2783
5	you	2624
6	and	2321
7	it	2158
8	is	2115
9	in	1986
10	for	1854
11	im	1676
12	of	1638
13	me	1540
14	on	1488
15	so	1410
16	have	1345
17	that	1297
18	but	1267
19	good	1251
```
```python
plt.bar(temp['よく使われる言葉'], temp['count'])
plt.tight_layout()
```
### 感情ごとによく使われている単語表示
```python
# ポジティブな感情の抽出
Positive_sent = train[train['sentiment']=='positive']

top = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])
temp_positive = pd.DataFrame(top.most_common(20))
temp_positive.columns = ['Common_words','count']
temp_positive.style.background_gradient(cmap='Reds')
```
```
	Common_words	count
0	good	826
1	happy	730
2	love	697
3	day	456
4	thanks	439
5	great	364
6	fun	287
7	nice	267
8	mothers	259
9	hope	245
10	awesome	232
11	im	185
12	thank	180
13	like	167
14	best	154
15	wish	152
16	amazing	135
17	really	128
18	better	125
19	cool	119
```
```python
import plotly.express as px

fig = px.bar(temp_positive, x="count", y="Common_words", title='Most Commmon Positive Words', orientation='h', 
             width=700, height=700,color='Common_words')
fig.show()
```